"""
é˜¶æ®µä¸€å¿«é€Ÿæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹åŠ è½½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import torch
import pickle
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "model"))

def test_data_preprocessing():
    """æµ‹è¯•æ•°æ®é¢„å¤„ç†"""
    print("=== æµ‹è¯•æ•°æ®é¢„å¤„ç† ===")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    data_root = "./datasets/pdbbind"
    if not os.path.exists(data_root):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return False
    
    # æµ‹è¯•åˆ†å­å›¾æ„å»ºå™¨
    try:
        from molecular_graph import MolecularGraphBuilder
        builder = MolecularGraphBuilder(cutoff_radius=5.0, num_gaussians=16)
        print("âœ… åˆ†å­å›¾æ„å»ºå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ç‰¹å¾ç»´åº¦
        dims = builder.get_feature_dimensions()
        print(f"âœ… ç‰¹å¾ç»´åº¦: {dims}")
        
    except Exception as e:
        print(f"âŒ åˆ†å­å›¾æ„å»ºå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•ç®€åŒ–ç‰ˆæ„å»ºå™¨
    try:
        from prepare_stage1_data import Stage1GraphBuilder
        stage1_builder = Stage1GraphBuilder(cutoff_radius=5.0, num_gaussians=16)
        dims = stage1_builder.get_feature_dimensions()
        print(f"âœ… é˜¶æ®µä¸€å›¾æ„å»ºå™¨: {dims}")
        
    except Exception as e:
        print(f"âŒ é˜¶æ®µä¸€å›¾æ„å»ºå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True


def test_model_loading():
    """æµ‹è¯•ESAæ¨¡å‹åŠ è½½"""
    print("\n=== æµ‹è¯•ESAæ¨¡å‹åŠ è½½ ===")
    
    try:
        from esa.models import Estimator
        
        # åˆ›å»ºæµ‹è¯•æ¨¡å‹
        model = Estimator(
            task_type="regression",
            num_features=36,  # 10*2 + 16
            graph_dim=64,
            edge_dim=None,
            batch_size=2,
            lr=1e-4,
            linear_output_size=1,
            apply_attention_on="edge",
            layer_types=["M", "M"],
            hidden_dims=[64, 64],
            num_heads=4,
            set_max_items=100
        )
        
        print(f"âœ… ESAæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"âœ… å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ESAæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_format():
    """æµ‹è¯•æ•°æ®æ ¼å¼"""
    print("\n=== æµ‹è¯•æ•°æ®æ ¼å¼ ===")
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é¢„å¤„ç†æ•°æ®
    stage1_dir = "./experiments/stage1"
    data_files = ["train.pkl", "valid.pkl", "test.pkl", "metadata.json"]
    
    all_exist = True
    for file in data_files:
        file_path = os.path.join(stage1_dir, file)
        if os.path.exists(file_path):
            print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file}")
        else:
            print(f"âŒ ç¼ºå°‘æ–‡ä»¶: {file}")
            all_exist = False
    
    if not all_exist:
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†: python prepare_stage1_data.py --test_run")
        return False
    
    # æµ‹è¯•åŠ è½½æ•°æ®
    try:
        # åŠ è½½å…ƒæ•°æ®
        with open(os.path.join(stage1_dir, "metadata.json"), 'r') as f:
            metadata = json.load(f)
        
        print(f"âœ… å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
        print(f"   ç‰¹å¾ç»´åº¦: {metadata['feature_dimensions']}")
        print(f"   æ•°æ®é›†ç»Ÿè®¡: {list(metadata['dataset_stats'].keys())}")
        
        # åŠ è½½ä¸€ä¸ªæ ·æœ¬æµ‹è¯•
        with open(os.path.join(stage1_dir, "train.pkl"), 'rb') as f:
            train_data = pickle.load(f)
        
        if len(train_data) > 0:
            sample = train_data[0]
            print(f"âœ… è®­ç»ƒæ•°æ®åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(train_data)}")
            print(f"   ç¬¬ä¸€ä¸ªæ ·æœ¬:")
            print(f"   - è¾¹è¡¨ç¤ºå½¢çŠ¶: {sample['edge_representations'].shape}")
            print(f"   - è¾¹æ•°: {sample['num_edges']}")
            print(f"   - èŠ‚ç‚¹æ•°: {sample['num_nodes']}")
            print(f"   - äº²å’ŒåŠ›: {sample['affinity']:.2f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ ¼å¼æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_training_components():
    """æµ‹è¯•è®­ç»ƒç»„ä»¶"""
    print("\n=== æµ‹è¯•è®­ç»ƒç»„ä»¶ ===")
    
    try:
        from experiments.stage1.train_stage1 import Stage1Dataset, collate_fn
        
        # æ£€æŸ¥æ•°æ®é›†ç±»
        stage1_dir = "./experiments/stage1"
        train_file = os.path.join(stage1_dir, "train.pkl")
        
        if not os.path.exists(train_file):
            print("âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡è®­ç»ƒç»„ä»¶æµ‹è¯•")
            return False
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = Stage1Dataset(train_file)
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œå¤§å°: {len(dataset)}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        from torch.utils.data import DataLoader
        
        dataloader = DataLoader(
            dataset, 
            batch_size=2, 
            shuffle=False,
            collate_fn=collate_fn
        )
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(dataloader))
        print(f"âœ… æ•°æ®åŠ è½½å™¨æµ‹è¯•æˆåŠŸ")
        print(f"   æ‰¹æ¬¡é”®: {list(batch.keys())}")
        print(f"   xå½¢çŠ¶: {batch['x'].shape}")
        print(f"   yå½¢çŠ¶: {batch['y'].shape}")
        print(f"   æœ€å¤§è¾¹æ•°: {batch['num_max_items']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª é˜¶æ®µä¸€ç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("æ•°æ®é¢„å¤„ç†", test_data_preprocessing),
        ("æ¨¡å‹åŠ è½½", test_model_loading), 
        ("æ•°æ®æ ¼å¼", test_data_format),
        ("è®­ç»ƒç»„ä»¶", test_training_components)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å‡ºç°å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 50)
    print("ğŸ æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)
    
    all_passed = True
    for test_name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if not passed:
            all_passed = False
    
    print("\n" + "=" * 50)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹é˜¶æ®µä¸€è®­ç»ƒ")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œæ•°æ®é¢„å¤„ç†ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰:")
        print("   python prepare_stage1_data.py --test_run")
        print("2. å¼€å§‹è®­ç»ƒ:")
        print("   bash run_stage1.sh test")
    else:
        print("âš ï¸  å­˜åœ¨æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
        print("\nå»ºè®®:")
        print("1. ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–")
        print("2. ç¡®ä¿PDBbindæ•°æ®é›†å·²æ­£ç¡®æ”¾ç½®")
        print("3. æ£€æŸ¥model/esaç›®å½•æ˜¯å¦å­˜åœ¨")


if __name__ == "__main__":
    main()
